{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0569b95b",
   "metadata": {},
   "source": [
    "### Notebook to complete in class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "febf23cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import gym\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from Plotting import plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51594f6c",
   "metadata": {},
   "source": [
    "#### Grace Lindsay Example\n",
    "\n",
    "<img src=\"./imgs/Lindsay.png\" width=\"350px\" align=\"left\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0559bbf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here the transition edges:\n",
      "--------------------------\n",
      "0 : [1, 6]\n",
      "1 : [2, 3]\n",
      "2 : [4]\n",
      "3 : [4, 5]\n",
      "4 : [8]\n",
      "5 : [7]\n",
      "6 : [7]\n",
      "7 : [8]\n",
      "8 : []\n"
     ]
    }
   ],
   "source": [
    "S = {0:\"GRE\", 1:\"COU\", 2:\"QUE\", 3:\"TIM\", 4:\"34t\", 5:\"14t\", 6:\"MET\", 7:\"UNI\", 8:\"BLE\"}\n",
    "A = {0:[0,1], 1:[0,1], 2:[0],   3:[0,1], 4:[0],   5:[0],   6:[0],   7:[0],   8:[]}\n",
    "T = {0:[1,6], 1:[2,3], 2:[4],   3:[4,5], 4:[8],   5:[7],   6:[7],   7:[8],   8:[]}\n",
    "\n",
    "# 1) Define the reward function as a dictionary:\n",
    "R = {}\n",
    "\n",
    "Q = {}        \n",
    "for s in S:\n",
    "    for a in A[s]:\n",
    "        Q[(s,a)] = 0   # We initialize the Value function\n",
    "\n",
    "# 2) define the reset function: returns the initial state\n",
    "\n",
    "# 3) define the step function: given an action, returns next state, reward and done\n",
    "\n",
    "\n",
    "def printQ(Q):\n",
    "    print(\"\\nQ value table:\\n---------------\")\n",
    "    for s in S:\n",
    "        if len(A[s]) > 0 and s in R:\n",
    "            Vs = R[s] + gamma*max([Q[(s,a)] for a in A[s]])\n",
    "            print(S[s], \":\", round(Vs,2))            \n",
    "\n",
    "print(\"Here the transition edges:\\n--------------------------\")\n",
    "for i,s in S.items():\n",
    "    print(i, \":\", [T[i][a] for a in A[i]])\n",
    "    \n",
    "# 4) print also the transitions as their names GRE : [COU, MET] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c72d2dfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Q value table:\n",
      "---------------\n"
     ]
    }
   ],
   "source": [
    "alpha, gamma = 0.2, 0.8\n",
    "\n",
    "def episode(bPrint=False):\n",
    "    s = reset()\n",
    "    done = False\n",
    "    while not done:    # trials loop    \n",
    "        a = random.choice(A[s])\n",
    "        s_next, r, done = step(s,a)      # transition function from environment\n",
    "        q_max_S_next = max([Q[(s_next, a_)] for a_ in A[s_next]]) if not done else 0    \n",
    "        if not done:\n",
    "            # 5) complete the computation of the TD_error:\n",
    "            TD_error = 0\n",
    "\n",
    "            # 5) complete the computation of the state-action value function update:\n",
    "            Q[(s,a)] = Q[(s,a)]\n",
    "\n",
    "        if bPrint: print(\"Was in\", s, \"did action\", a, \"got in\", s_next, \"and made %d$\"%r, \"and I'm done\" if done else \"\")\n",
    "        s = s_next\n",
    "\n",
    "        \n",
    "# 6) Perform a loop of 100 episodes  \n",
    "    \n",
    "    \n",
    "printQ(Q) # We print the resulting Q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b5c5ee5",
   "metadata": {},
   "source": [
    "### Plotting Exercise\n",
    "Make a TD_Error evolution plot, the one you want. You will need to modify the previous function episode(). You can use the function plot that we used in the AddictionRedish notebook imported here from Plotting.py as plot: <BR>\n",
    "\n",
    "`def plot(td_list, ax=None, color=None, label=None, title=None, xlabel='Updates', ylabel='Error', ylim=None, marker=None)` <br>\n",
    "\n",
    "and can be called with a list of values: <br>\n",
    "    \n",
    "`plot(td_errors)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f28d59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9d8fa47c",
   "metadata": {},
   "source": [
    "### Introducing a Q function class\n",
    "\n",
    "We defined the Q function as a dictionary. We are now going to define the Q function as a class with two main functions \"predict\" and \"update\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5ae4b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Q_function():  \n",
    "    def __init__(self, env):       \n",
    "        self.nactions = env.nactions   \n",
    "        self.f = {}\n",
    "        \n",
    "    def predict(self, s, a=None):  # get value of a state (s) and action (a)\n",
    "        if s not in self.f:\n",
    "             self.f[s] = [0]*self.nactions       \n",
    "        return self.f[s] if a is None else self.f[s][a]\n",
    "    \n",
    "    def update(self, s, a, y):     # update couplet state, action (s, a) with y\n",
    "        self.f[s][a] = y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec44a1d0",
   "metadata": {},
   "source": [
    "### Introducing an Object Oriented class: Q_function Exercises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "96ad45c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a Q_function and test to set the following function:\n",
    "#   States are ['BCN', 'MAD', 'BIL', 'VAL'], \n",
    "#   all states have initial value 0 except BCN that has value 10\n",
    "#   query the values of the Q_function, BCN, MAD for example\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "77ea2bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Redefine the previous function episode() with the new class Q_funtion\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced0b2a7",
   "metadata": {},
   "source": [
    "### Introducing a policy class\n",
    "\n",
    "We defined the Policy Class to be able to implement epsilon greedy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "33dd8149",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Policy():  \n",
    "    def __init__(self, Q):       \n",
    "        self.nactions = len(A)   \n",
    "        self.Q = Q\n",
    " \n",
    "    def act(self, state, epsilon):\n",
    "        if isinstance(Q,dict):\n",
    "            q_values = [Q[(state,a)] for a in A[state]]\n",
    "        else:\n",
    "            q_values = Q.predict(state)\n",
    "        \n",
    "        if np.random.uniform() < epsilon:\n",
    "            return np.random.randint(env.nactions)   # explore\n",
    "        else:\n",
    "            return np.argmax(q_values)               # exploit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ee83f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a Policy and test it. For example, found out what to do in state 0 (GRE).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c5108c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Redefine the previous function episode() with the new class Policy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f142212a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate wht is the improvment in learning speed when using a greedy policy\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
