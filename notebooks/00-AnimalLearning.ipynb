{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rescorla-Wagner Model of Classical Conditioning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1. Initializing association weights $w \\in \\mathbb{R}^n$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7099717143963378, 0.8007649148606881]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[np.random.uniform() for _ in range(2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w: [0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# define w\n",
    "n_feat = 2  # CSes like bell and light \n",
    "w = np.random.uniform(high=0.0001, size=2)\n",
    "print(\"w:\", np.round(w,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2. Defining value of a Stimulus vector $x$\n",
    "Given: $w$ weight vector and stimulus vector $x$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0.]\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "x = [1, 0] # bell, be careful its a python list\n",
    "x = np.array(x)\n",
    "l = [w[i]*x[i] for i in range(len(x))]\n",
    "print(np.round(l,2))\n",
    "print(np.round(np.sum(l),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value:  1.5\n"
     ]
    }
   ],
   "source": [
    "# define a function, call it value (receives as input w and x)\n",
    "def value(w,x):\n",
    "    sum_value = 0\n",
    "    for i,wi in enumerate(w):\n",
    "        sum_value = sum_value + wi*x[i]\n",
    "    return sum_value\n",
    "\n",
    "# Testing the value function in this situation: \n",
    "print(\"Value: \",value(w=[1,0.5],x=[1,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3. Defining associative weight update $\\Delta w$\n",
    "$x$: stimulus vector, $r$: reward, $\\alpha$: learning rate, n_times: number of updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the weight update \n",
    "def update_rw(w, x, r=1, alpha=0.5, n_times=1):  # times being trials\n",
    "    x = np.array(x)\n",
    "    for _ in range(n_times):\n",
    "        td_error = r - value(w,x)\n",
    "        w = w + alpha*td_error*x\n",
    "    return w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4. Define Classical Conditioning paradigms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> w after A->+: [0.999 0.   ]\n",
      "> w after AB->+ [1. 0.]\n",
      "Value of B->? 0.0\n"
     ]
    }
   ],
   "source": [
    "# take the example of forward blocking and define all steps to test results with the model\n",
    "# 1) initialize weights w and stimulus x\n",
    "# 2) update weights 10 times for A -> + association\n",
    "# 3) update weights 10 times for AB -> + association\n",
    "# 4) print the value of B?\n",
    "\n",
    "w = np.array([0,0])\n",
    "\n",
    "# First phase A->+\n",
    "x = [1,0]\n",
    "w = update_rw(w,x,r=1, n_times=10)\n",
    "print(\"> w after A->+:\", np.round(w,4))\n",
    "\n",
    "# Second AB -> +\n",
    "x = [1,1]\n",
    "w = update_rw(w,x,r=1, n_times=10)\n",
    "\n",
    "print(\"> w after AB->+\", np.round(w,3))\n",
    "print(\"Value of B->?\", np.round(value(w,[0,1]),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overexpectation -------\n",
      "> w init: [0. 0.]\n",
      "> w after A->+: [1. 0.]\n",
      "> w after B->+: [1. 1.]\n",
      "Value of B->? 1.0\n",
      "> w after AB->+ [0.5 0.5]\n",
      "Value of B->? 0.5\n"
     ]
    }
   ],
   "source": [
    "def overexpectation():\n",
    "    print(\"overexpectation -------\")\n",
    "    w = np.random.uniform(high=0.001, size=n_feat)\n",
    "    print(\"> w init:\", np.round(w,2))\n",
    "    x = [1,0]\n",
    "    w = update_rw(w, x, n_times=10)\n",
    "    print(\"> w after A->+:\", np.round(w,2))\n",
    "    x = [0,1]\n",
    "    w = update_rw(w, x, n_times=10)\n",
    "    print(\"> w after B->+:\", np.round(w,2))\n",
    "    print(\"Value of B->?\", np.round(value(w,[0,1]),2))\n",
    "    \n",
    "    w = update_rw(w,[1,1], n_times=10)\n",
    "    print(\"> w after AB->+\", np.round(w,2))\n",
    "    \n",
    "    print(\"Value of B->?\", np.round(value(w,[0,1]),2))\n",
    "\n",
    "    \n",
    "overexpectation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overshadowing -------\n",
      "> w init: [0. 0.]\n",
      "> w after AB->+ [0.5 0.5]\n",
      "Value of B->? 0.5\n"
     ]
    }
   ],
   "source": [
    "def overshadowing():\n",
    "    print(\"overshadowing -------\")\n",
    "    w = np.random.uniform(high=0.001, size=n_feat)\n",
    "    print(\"> w init:\", np.round(w,2))\n",
    "    w = update_rw(w,[1,1], n_times=10)\n",
    "    print(\"> w after AB->+\", np.round(w,2))\n",
    "    print(\"Value of B->?\", np.round(value(w,[0,1]),2))\n",
    "\n",
    "    \n",
    "overshadowing()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Temoral Difference Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution 1. Future discounted reward prediction within R&W \n",
    "Function approximation $V_t = w^\\top \\phi(s_t)$ and Indicator features $x_t = \\phi(s_t) \\in \\mathbb{R}^n$ sets a 1 at the corresponding state index (one-hot encoding): $x_t(t) = 1$  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the weight update \n",
    "def update_td(w, x, x_next, r=1, alpha=0.5, gamma=0.8, n_times=1):  # times being trials\n",
    "    x = np.array(x)\n",
    "    for _ in range(n_times):\n",
    "        td_error = r + gamma*value(w, x_next) - value(w,x)\n",
    "        w = w + alpha*td_error*x\n",
    "    return w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second Order Conditioning is now captured:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w after B->+ [0.         0.99902344]\n",
      "w after A->B [0.79921875 0.99902344]\n",
      "Value of A->? 0.8\n"
     ]
    }
   ],
   "source": [
    "# Our aim is to test Second Order Conditioning: \n",
    "# B->+,   A->B,   A->?\n",
    "w = [0,0]\n",
    "\n",
    "A = [1,0]\n",
    "B = [0,1]\n",
    "\n",
    "# B->+\n",
    "w = update_td(w, x=B, x_next=[0,0], r=1, n_times=10)  # with a dummy next state [0,0]\n",
    "print(\"w after B->+\", w)\n",
    "\n",
    "# A->B\n",
    "w = update_td(w, A, B, r=0, gamma=.8, n_times=100)\n",
    "print(\"w after A->B\", w)\n",
    "\n",
    "# Value of A after training?\n",
    "print(\"Value of A->?\", np.round(value(w,[1,0]),2))   # Now second order conditioning works!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution 2. Global states, no feature approximation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initializations\n",
    "alpha=0.5\n",
    "gamma=0.8\n",
    "t=0               # will index time steps, 0,1,2\n",
    "R = [0,1,0]       # defines the reward at time t:  corresponds to A,B,dummy next state  \n",
    "S = [0,1,2]       # states are represented as integers A=0, B=1\n",
    "A,B = 0,1\n",
    "V = np.zeros(3)   # we use an array to store the state value: no association weight vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value of B after B->+ (V[B]): 0.9990234375\n",
      "Value of A after A->B (V[A]): 0.7984382629394532\n"
     ]
    }
   ],
   "source": [
    "# B->+\n",
    "t = 1\n",
    "for _ in range(10): \n",
    "    td_error = R[t] + gamma*V[t+1] - V[t] \n",
    "    V[t] = V[t] + alpha*td_error\n",
    "\n",
    "print(\"Value of B after B->+ (V[B]):\", V[B])\n",
    "\n",
    "# A->B\n",
    "t = 0\n",
    "for _ in range(10): \n",
    "    td_error = R[t] + gamma*V[t+1] - V[t] \n",
    "    V[t] = V[t] + alpha*td_error\n",
    "\n",
    "print(\"Value of A after A->B (V[A]):\", V[A])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
