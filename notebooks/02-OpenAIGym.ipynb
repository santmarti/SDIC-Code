{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# System Design Integration and Control - Part II\n",
    "\n",
    "### Open AI Gym Environments\n",
    "Gym is a standard for RL environments and is coupled with other simulation environments: Box2D, Mujoco, etc... Either install it with:  \n",
    "\n",
    "`pip install gym`\n",
    "\n",
    "or alternatively\n",
    "\n",
    "`git clone https://github.com/openai/gym` <br>\n",
    "`cd gym` <br>\n",
    "`pip install -e .` <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environment Instance Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observation Space: Discrete(16)\n",
      "Action Space: Discrete(4)\n",
      "Observation after reset: 0\n",
      "The action space can be sampled, for example: 2\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"FrozenLake-v1\",  is_slippery=False)\n",
    "print(\"Observation Space: \" + str(env.observation_space))\n",
    "print(\"Action Space: \" + str(env.action_space))\n",
    "observation = env.reset()\n",
    "print(\"Observation after reset: \" + str(observation))\n",
    "print(\"The action space can be sampled, for example:\", env.action_space.sample())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Environments can be rendered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n"
     ]
    }
   ],
   "source": [
    "env.render()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding Environment\n",
    "\n",
    "The __State__ space is : _Discrete_? _Continuous_? <br>\n",
    "How many dimensions it has? <br>\n",
    "What is the state data type? <br>\n",
    "\n",
    "The __Action__ space is _Discrete_? _Continuous_? <br>\n",
    "How many actions? <br>\n",
    "What is the action data type? <br>\n",
    "\n",
    "Is the environment __episodic__, runs in episodes? terminates? When? <br>\n",
    "\n",
    "And what characterizes the reward, is it: negative? positive? discrete? continuous? smooth? sparse? <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agent takes steps in the environment receives: <font color=blue> new obs, reward, done and info  </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "obs 4 rew 0.0 done False\n",
      "  (Down)\n",
      "SFFF\n",
      "\u001b[41mF\u001b[0mHFH\n",
      "FFFH\n",
      "HFFG\n"
     ]
    }
   ],
   "source": [
    "#observation = env.reset()\n",
    "env.render()\n",
    "observation, reward, done, info = env.step(1)\n",
    "print(\"obs\", observation, \"rew\", reward, \"done\", done)\n",
    "env.render()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets define the Agent-Environment Loop: One Episode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "obs 0 rew 0.0 done False\n",
      "obs 0 rew 0.0 done False\n",
      "obs 0 rew 0.0 done False\n",
      "obs 0 rew 0.0 done False\n",
      "obs 0 rew 0.0 done False\n",
      "obs 4 rew 0.0 done False\n",
      "obs 8 rew 0.0 done False\n",
      "obs 9 rew 0.0 done False\n",
      "obs 10 rew 0.0 done False\n",
      "obs 11 rew 0.0 done True\n"
     ]
    }
   ],
   "source": [
    "done = False\n",
    "obs = env.reset()\n",
    "while not done:\n",
    "    action = env.action_space.sample()\n",
    "    obs, rew, done, _ = env.step(action)\n",
    "    print(\"obs\",obs,\"rew\",rew, \"done\", done)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Agent-Environment Loop : run one and several episodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode ended sum_reward = 11.0\n",
      "Episode ended sum_reward = 23.0\n",
      "Episode ended sum_reward = 24.0\n",
      "Episode ended sum_reward = 25.0\n",
      "Episode ended sum_reward = 23.0\n",
      "Episode ended sum_reward = 17.0\n",
      "Episode ended sum_reward = 22.0\n",
      "Episode ended sum_reward = 22.0\n",
      "Episode ended sum_reward = 13.0\n",
      "Episode ended sum_reward = 13.0\n"
     ]
    }
   ],
   "source": [
    "def run_episode(bRender=False, model=None):\n",
    "    done = False\n",
    "    obs = env.reset()\n",
    "    sum_reward = 0\n",
    "    while not done:\n",
    "        if model == None:\n",
    "            action = env.action_space.sample()\n",
    "        else:\n",
    "            action, _ = model.predict(obs, deterministic=True)\n",
    "        obs, rew, done, _ = env.step(action)\n",
    "        sum_reward += rew\n",
    "        if bRender:\n",
    "            env.render()\n",
    "        #print(\"obs\",obs,\"rew\",rew, \"done\", done)\n",
    "    print(\"Episode ended sum_reward =\",sum_reward)\n",
    "    return rew\n",
    "    \n",
    "for i in range(10):\n",
    "    run_episode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode ended sum_reward = 11.0\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"CartPole-v1\")\n",
    "run_episode(bRender=True)\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For using Box2D (physics library) environments like LunarLander-v2 you need to install library box2d in addition to gym\n",
    "`pip install box2d`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode ended sum_reward = -472.4686204662702\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"LunarLander-v2\")\n",
    "run_episode(bRender=True)\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Libraries for solving Gym Environments \n",
    "\n",
    "https://stable-baselines3.readthedocs.io/en/master/ <br>\n",
    "https://github.com/AI4Finance-Foundation/ElegantRL <br>\n",
    "https://docs.ray.io/en/latest/rllib/index.html <br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode ended sum_reward = 156.0\n"
     ]
    }
   ],
   "source": [
    "from stable_baselines3 import PPO\n",
    "\n",
    "env = gym.make(\"CartPole-v1\")\n",
    "model = PPO(\"MlpPolicy\", env, verbose=1)\n",
    "model.learn(total_timesteps=10000)\n",
    "\n",
    "run_episode(bRender=True, model=model)\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 88.2     |\n",
      "|    ep_rew_mean     | -192     |\n",
      "| time/              |          |\n",
      "|    fps             | 1761     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 1        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 88.1        |\n",
      "|    ep_rew_mean          | -170        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1336        |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 3           |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008924368 |\n",
      "|    clip_fraction        | 0.0343      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.38       |\n",
      "|    explained_variance   | -0.0086     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 678         |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.00606    |\n",
      "|    value_loss           | 1.68e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 92.7        |\n",
      "|    ep_rew_mean          | -163        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1277        |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 4           |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008530354 |\n",
      "|    clip_fraction        | 0.0399      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.37       |\n",
      "|    explained_variance   | -0.0189     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 243         |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.011      |\n",
      "|    value_loss           | 977         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 96.5         |\n",
      "|    ep_rew_mean          | -162         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1257         |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 6            |\n",
      "|    total_timesteps      | 8192         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0078101465 |\n",
      "|    clip_fraction        | 0.0381       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.35        |\n",
      "|    explained_variance   | 0.00552      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 305          |\n",
      "|    n_updates            | 30           |\n",
      "|    policy_gradient_loss | -0.00497     |\n",
      "|    value_loss           | 674          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 101         |\n",
      "|    ep_rew_mean          | -168        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1223        |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 8           |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011959435 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.31       |\n",
      "|    explained_variance   | 0.00112     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 313         |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0116     |\n",
      "|    value_loss           | 617         |\n",
      "-----------------------------------------\n",
      "Episode ended sum_reward = -858.0899522358718\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"LunarLander-v2\")\n",
    "model = PPO(\"MlpPolicy\", env, verbose=1)\n",
    "model.learn(total_timesteps=10000)\n",
    "\n",
    "run_episode(bRender=True, model=model)\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 338      |\n",
      "|    ep_rew_mean     | -116     |\n",
      "| time/              |          |\n",
      "|    fps             | 1333     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 1        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 216         |\n",
      "|    ep_rew_mean          | -117        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1076        |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 3           |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008955124 |\n",
      "|    clip_fraction        | 0.08        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.7        |\n",
      "|    explained_variance   | -0.00918    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 105         |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0104     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 192         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 338          |\n",
      "|    ep_rew_mean          | -115         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1037         |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 5            |\n",
      "|    total_timesteps      | 6144         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068068914 |\n",
      "|    clip_fraction        | 0.0395       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.72        |\n",
      "|    explained_variance   | 0.167        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 125          |\n",
      "|    n_updates            | 20           |\n",
      "|    policy_gradient_loss | -0.00972     |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 189          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 327          |\n",
      "|    ep_rew_mean          | -114         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 994          |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 8            |\n",
      "|    total_timesteps      | 8192         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073822383 |\n",
      "|    clip_fraction        | 0.0792       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.73        |\n",
      "|    explained_variance   | 0.0048       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 108          |\n",
      "|    n_updates            | 30           |\n",
      "|    policy_gradient_loss | -0.00894     |\n",
      "|    std                  | 1.02         |\n",
      "|    value_loss           | 111          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 271          |\n",
      "|    ep_rew_mean          | -114         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 976          |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 10           |\n",
      "|    total_timesteps      | 10240        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0057171155 |\n",
      "|    clip_fraction        | 0.0476       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.76        |\n",
      "|    explained_variance   | 0.409        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 53.3         |\n",
      "|    n_updates            | 40           |\n",
      "|    policy_gradient_loss | -0.00592     |\n",
      "|    std                  | 1.03         |\n",
      "|    value_loss           | 144          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 321         |\n",
      "|    ep_rew_mean          | -113        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 959         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 12          |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007003127 |\n",
      "|    clip_fraction        | 0.0384      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.77       |\n",
      "|    explained_variance   | 0.597       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 69.2        |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0105     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 136         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 348         |\n",
      "|    ep_rew_mean          | -113        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 946         |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 15          |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009399867 |\n",
      "|    clip_fraction        | 0.0763      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.77       |\n",
      "|    explained_variance   | 0.666       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 51.8        |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0128     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 75.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 379         |\n",
      "|    ep_rew_mean          | -113        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 925         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 17          |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012401686 |\n",
      "|    clip_fraction        | 0.16        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.77       |\n",
      "|    explained_variance   | 0.576       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.7         |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.00796    |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 21.6        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 408        |\n",
      "|    ep_rew_mean          | -113       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 913        |\n",
      "|    iterations           | 9          |\n",
      "|    time_elapsed         | 20         |\n",
      "|    total_timesteps      | 18432      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01230287 |\n",
      "|    clip_fraction        | 0.15       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -5.75      |\n",
      "|    explained_variance   | 0.532      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.138      |\n",
      "|    n_updates            | 80         |\n",
      "|    policy_gradient_loss | -0.00844   |\n",
      "|    std                  | 1.01       |\n",
      "|    value_loss           | 1.15       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 462          |\n",
      "|    ep_rew_mean          | -112         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 913          |\n",
      "|    iterations           | 10           |\n",
      "|    time_elapsed         | 22           |\n",
      "|    total_timesteps      | 20480        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0151901115 |\n",
      "|    clip_fraction        | 0.175        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.68        |\n",
      "|    explained_variance   | 0.202        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0507       |\n",
      "|    n_updates            | 90           |\n",
      "|    policy_gradient_loss | -0.0132      |\n",
      "|    std                  | 0.992        |\n",
      "|    value_loss           | 0.41         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 487         |\n",
      "|    ep_rew_mean          | -111        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 913         |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 24          |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009828264 |\n",
      "|    clip_fraction        | 0.0928      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.61       |\n",
      "|    explained_variance   | -0.148      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.297       |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.0089     |\n",
      "|    std                  | 0.976       |\n",
      "|    value_loss           | 0.418       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 493         |\n",
      "|    ep_rew_mean          | -111        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 888         |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 27          |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011944307 |\n",
      "|    clip_fraction        | 0.135       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.54       |\n",
      "|    explained_variance   | 0.226       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.047       |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.0128     |\n",
      "|    std                  | 0.962       |\n",
      "|    value_loss           | 0.31        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 498          |\n",
      "|    ep_rew_mean          | -110         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 894          |\n",
      "|    iterations           | 13           |\n",
      "|    time_elapsed         | 29           |\n",
      "|    total_timesteps      | 26624        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026763733 |\n",
      "|    clip_fraction        | 0.01         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.52        |\n",
      "|    explained_variance   | 0.0602       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.602        |\n",
      "|    n_updates            | 120          |\n",
      "|    policy_gradient_loss | -0.00349     |\n",
      "|    std                  | 0.963        |\n",
      "|    value_loss           | 53.6         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 540         |\n",
      "|    ep_rew_mean          | -109        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 897         |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 31          |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005145667 |\n",
      "|    clip_fraction        | 0.0308      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.52       |\n",
      "|    explained_variance   | 0.609       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 44.5        |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.00463    |\n",
      "|    std                  | 0.959       |\n",
      "|    value_loss           | 35          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 550         |\n",
      "|    ep_rew_mean          | -109        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 901         |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 34          |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008510672 |\n",
      "|    clip_fraction        | 0.11        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.48       |\n",
      "|    explained_variance   | 0.46        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.279       |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.00932    |\n",
      "|    std                  | 0.945       |\n",
      "|    value_loss           | 0.875       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 560          |\n",
      "|    ep_rew_mean          | -108         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 906          |\n",
      "|    iterations           | 16           |\n",
      "|    time_elapsed         | 36           |\n",
      "|    total_timesteps      | 32768        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0082627535 |\n",
      "|    clip_fraction        | 0.0732       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.43        |\n",
      "|    explained_variance   | 0.199        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 34.7         |\n",
      "|    n_updates            | 150          |\n",
      "|    policy_gradient_loss | -0.00902     |\n",
      "|    std                  | 0.937        |\n",
      "|    value_loss           | 20.6         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 578         |\n",
      "|    ep_rew_mean          | -108        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 911         |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 38          |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008331779 |\n",
      "|    clip_fraction        | 0.0717      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.39       |\n",
      "|    explained_variance   | 0.716       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.93        |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.00906    |\n",
      "|    std                  | 0.926       |\n",
      "|    value_loss           | 12.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 612         |\n",
      "|    ep_rew_mean          | -107        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 915         |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 40          |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009786762 |\n",
      "|    clip_fraction        | 0.127       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.34       |\n",
      "|    explained_variance   | -1.27       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0823      |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.0077     |\n",
      "|    std                  | 0.915       |\n",
      "|    value_loss           | 0.372       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 628         |\n",
      "|    ep_rew_mean          | -107        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 918         |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 42          |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011269383 |\n",
      "|    clip_fraction        | 0.111       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.29       |\n",
      "|    explained_variance   | -0.545      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.184       |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.00839    |\n",
      "|    std                  | 0.903       |\n",
      "|    value_loss           | 0.283       |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 644         |\n",
      "|    ep_rew_mean          | -106        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 922         |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 44          |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006945964 |\n",
      "|    clip_fraction        | 0.0585      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.23       |\n",
      "|    explained_variance   | 0.171       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0745      |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.00605    |\n",
      "|    std                  | 0.889       |\n",
      "|    value_loss           | 0.199       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 659         |\n",
      "|    ep_rew_mean          | -106        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 924         |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 46          |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008777872 |\n",
      "|    clip_fraction        | 0.101       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.18       |\n",
      "|    explained_variance   | 0.724       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.228       |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.0111     |\n",
      "|    std                  | 0.879       |\n",
      "|    value_loss           | 0.161       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 688         |\n",
      "|    ep_rew_mean          | -105        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 308         |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 146         |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010223355 |\n",
      "|    clip_fraction        | 0.102       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.13       |\n",
      "|    explained_variance   | 0.294       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.177       |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.0107     |\n",
      "|    std                  | 0.865       |\n",
      "|    value_loss           | 0.231       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 702         |\n",
      "|    ep_rew_mean          | -105        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 316         |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 148         |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008361837 |\n",
      "|    clip_fraction        | 0.0824      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.07       |\n",
      "|    explained_variance   | 0.759       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.371       |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.00828    |\n",
      "|    std                  | 0.854       |\n",
      "|    value_loss           | 0.32        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 715         |\n",
      "|    ep_rew_mean          | -104        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 324         |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 151         |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009703354 |\n",
      "|    clip_fraction        | 0.134       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.03       |\n",
      "|    explained_variance   | 0.219       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0453      |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.0127     |\n",
      "|    std                  | 0.848       |\n",
      "|    value_loss           | 0.166       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 731         |\n",
      "|    ep_rew_mean          | -103        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 331         |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 154         |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008695837 |\n",
      "|    clip_fraction        | 0.0942      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.98       |\n",
      "|    explained_variance   | 0.377       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0216      |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.0092     |\n",
      "|    std                  | 0.833       |\n",
      "|    value_loss           | 0.158       |\n",
      "-----------------------------------------\n",
      "Episode ended sum_reward = -43.94086021571162\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"BipedalWalker-v3\")\n",
    "model = PPO(\"MlpPolicy\", env, verbose=1)\n",
    "model.learn(total_timesteps=50000)\n",
    "\n",
    "run_episode(bRender=True, model=model)\n",
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
