{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 514,
     "status": "ok",
     "timestamp": 1614260776023,
     "user": {
      "displayName": "MARTI SANCHEZ FIBLA",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhlfNrQFQQXOaTc4NN78MRNzmsOYLcRUr-tGn9r=s64",
      "userId": "08353041956880814737"
     },
     "user_tz": -60
    },
    "id": "asp5jZnyac7f"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hQ-I9ibzac7k"
   },
   "source": [
    "# Rescorla-Wagner Model of Classical Conditioning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_P8gZRthac7l"
   },
   "source": [
    "### Step 1. Initializing association weights $w \\in \\mathbb{R}^n$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JCHK-6D5ac7m",
    "outputId": "95724074-5158-438d-b475-d814dfa2e623"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7099717143963378, 0.8007649148606881]"
      ]
     },
     "execution_count": 2,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[np.random.uniform() for _ in range(2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IvEjFMmzac7o",
    "outputId": "00d910dc-5d1d-4180-b87a-cd17d1c4bee0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w: [0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# define w\n",
    "n_feat = 2  # CSes like bell and light \n",
    "w = np.random.uniform(high=0.0001, size=2)\n",
    "print(\"w:\", np.round(w,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cpcy6LC_ac7o"
   },
   "source": [
    "### Step 2. Defining value of a Stimulus vector $x$\n",
    "Given: $w$ weight vector and stimulus vector $x$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gNQXyYcUac7p",
    "outputId": "aeb9ee67-f6e3-4a6d-e4c5-ae04b00f8791"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0.]\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "x = [1, 0] # bell, be careful its a python list\n",
    "x = np.array(x)\n",
    "l = [w[i]*x[i] for i in range(len(x))]\n",
    "print(np.round(l,2))\n",
    "print(np.round(np.sum(l),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_BeTNwv8ac7p",
    "outputId": "540a64c6-9040-45f0-90e8-a0c3d684ceb1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value:  1.5\n"
     ]
    }
   ],
   "source": [
    "# define a function, call it value (receives as input w and x)\n",
    "def value(w,x):\n",
    "    sum_value = 0\n",
    "    for i,wi in enumerate(w):\n",
    "        sum_value = sum_value + wi*x[i]\n",
    "    return sum_value\n",
    "\n",
    "# Testing the value function in this situation: \n",
    "print(\"Value: \",value(w=[1,0.5],x=[1,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3AjDaVt5ac7r"
   },
   "source": [
    "### Step 3. Defining associative weight update $\\Delta w$\n",
    "$x$: stimulus vector, $r$: reward, $\\alpha$: learning rate, n_times: number of updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Og4XUpZJac7r"
   },
   "outputs": [],
   "source": [
    "# define the weight update \n",
    "def update_rw(w, x, r=1, alpha=0.5, n_times=1):  # times being trials\n",
    "    x = np.array(x)\n",
    "    for _ in range(n_times):\n",
    "        td_error = r - value(w,x) # temporal difference error : reward that you got - predicted one\n",
    "        w = w + alpha*td_error*x\n",
    "    return w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LkJyl-Ikac7r"
   },
   "source": [
    "### Step 4. Define Classical Conditioning paradigms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CZx8FXTVac7s",
    "outputId": "bc291549-8dbe-44ae-9adc-8d9db059ed15"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> w after A->+: [0.999 0.   ]\n",
      "> w after AB->+ [1. 0.]\n",
      "Value of B->? 0.0\n"
     ]
    }
   ],
   "source": [
    "# take the example of forward blocking and define all steps to test results with the model\n",
    "# 1) initialize weights w and stimulus x\n",
    "# 2) update weights 10 times for A -> + association\n",
    "# 3) update weights 10 times for AB -> + association\n",
    "# 4) print the value of B?\n",
    "\n",
    "w = np.array([0,0])\n",
    "\n",
    "# First phase A->+\n",
    "x = [1,0]\n",
    "w = update_rw(w,x,r=1, n_times=10)\n",
    "print(\"> w after A->+:\", np.round(w,4))\n",
    "\n",
    "# Second AB -> +\n",
    "x = [1,1]\n",
    "w = update_rw(w,x,r=1, n_times=10)\n",
    "\n",
    "print(\"> w after AB->+\", np.round(w,3))\n",
    "print(\"Value of B->?\", np.round(value(w,[0,1]),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oltkCmLjac7s",
    "outputId": "7e0e6a12-ca67-4baa-df00-b522109fc487"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overexpectation -------\n",
      "> w init: [0. 0.]\n",
      "> w after A->+: [1. 0.]\n",
      "> w after B->+: [1. 1.]\n",
      "Value of B->? 1.0\n",
      "> w after AB->+ [0.5 0.5]\n",
      "Value of B->? 0.5\n"
     ]
    }
   ],
   "source": [
    "def overexpectation():\n",
    "    print(\"overexpectation -------\")\n",
    "    w = np.random.uniform(high=0.001, size=n_feat)\n",
    "    print(\"> w init:\", np.round(w,2))\n",
    "    x = [1,0]\n",
    "    w = update_rw(w, x, n_times=10)\n",
    "    print(\"> w after A->+:\", np.round(w,2))\n",
    "    x = [0,1]\n",
    "    w = update_rw(w, x, n_times=10)\n",
    "    print(\"> w after B->+:\", np.round(w,2))\n",
    "    print(\"Value of B->?\", np.round(value(w,[0,1]),2))\n",
    "    \n",
    "    w = update_rw(w,[1,1], n_times=10)\n",
    "    print(\"> w after AB->+\", np.round(w,2))\n",
    "    \n",
    "    print(\"Value of B->?\", np.round(value(w,[0,1]),2))\n",
    "\n",
    "    \n",
    "overexpectation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oJhyE2fkac7u",
    "outputId": "e0c2a740-da5e-4316-e6f9-e044095fbe0f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overshadowing -------\n",
      "> w init: [0. 0.]\n",
      "> w after AB->+ [0.5 0.5]\n",
      "Value of B->? 0.5\n"
     ]
    }
   ],
   "source": [
    "def overshadowing():\n",
    "    print(\"overshadowing -------\")\n",
    "    w = np.random.uniform(high=0.001, size=n_feat)\n",
    "    print(\"> w init:\", np.round(w,2))\n",
    "    w = update_rw(w,[1,1], n_times=10)\n",
    "    print(\"> w after AB->+\", np.round(w,2))\n",
    "    print(\"Value of B->?\", np.round(value(w,[0,1]),2))\n",
    "\n",
    "    \n",
    "overshadowing()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sY0KPsh6ac7u"
   },
   "source": [
    "# Temporal Difference Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bK-AbqXsac7u"
   },
   "source": [
    "### Solution 1. Future discounted reward prediction within R&W \n",
    "Function approximation $V_t = w^\\top \\phi(s_t)$ and Indicator features $x_t = \\phi(s_t) \\in \\mathbb{R}^n$ sets a 1 at the corresponding state index (one-hot encoding): $x_t(t) = 1$  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A4j1KJIcac7v"
   },
   "outputs": [],
   "source": [
    "# define the weight update \n",
    "def update_td(w, x, x_next, r=1, alpha=0.5, gamma=0.8, n_times=1):  # times being trials\n",
    "    x = np.array(x)\n",
    "    for _ in range(n_times):\n",
    "        td_error = r + gamma*value(w, x_next) - value(w,x)\n",
    "        w = w + alpha*td_error*x\n",
    "    return w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0TnAO8IPac7v"
   },
   "source": [
    "Second Order Conditioning is now captured:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wDDkCLIxac7v",
    "outputId": "eb6d1cd1-d271-4565-f7eb-9ad34e7997f1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w after B->+ [0.         0.99902344]\n",
      "w after A->B [0.79921875 0.99902344]\n",
      "Value of A->? 0.8\n"
     ]
    }
   ],
   "source": [
    "# Our aim is to test Second Order Conditioning: \n",
    "# B->+,   A->B,   A->?\n",
    "w = [0,0]\n",
    "\n",
    "A = [1,0]\n",
    "B = [0,1]\n",
    "\n",
    "# B->+\n",
    "w = update_td(w, x=B, x_next=[0,0], r=1, n_times=10)  # with a dummy next state [0,0]\n",
    "print(\"w after B->+\", w)\n",
    "\n",
    "# A->B\n",
    "w = update_td(w, x=A, x_next=B, r=0, gamma=.8, n_times=100)\n",
    "print(\"w after A->B\", w)\n",
    "\n",
    "# Value of A after training?\n",
    "print(\"Value of A->?\", np.round(value(w,A),2))   # Now second order conditioning works!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f-Utz5f7ac7v"
   },
   "source": [
    "### Solution 2. Global states, no feature approximation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 975,
     "status": "ok",
     "timestamp": 1614262111266,
     "user": {
      "displayName": "MARTI SANCHEZ FIBLA",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhlfNrQFQQXOaTc4NN78MRNzmsOYLcRUr-tGn9r=s64",
      "userId": "08353041956880814737"
     },
     "user_tz": -60
    },
    "id": "kgB3N7D7ac7x"
   },
   "outputs": [],
   "source": [
    "# initializations\n",
    "alpha=0.5\n",
    "gamma=0.8         # gamma of 0 brings us back to R&W model\n",
    "t=0               # will index time steps, 0,1,2\n",
    "R = [0,1,0]       # defines the reward at time t:  corresponds to A,B,dummy next state  \n",
    "S = [0,1,2]       # states are represented as integers A=0, B=1\n",
    "A,B,C = 0,1,2\n",
    "V = np.zeros(3)   # V[0] = value of state 0: an array used to store \"value\" of each state: no association weight vector.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1342,
     "status": "ok",
     "timestamp": 1614262141128,
     "user": {
      "displayName": "MARTI SANCHEZ FIBLA",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhlfNrQFQQXOaTc4NN78MRNzmsOYLcRUr-tGn9r=s64",
      "userId": "08353041956880814737"
     },
     "user_tz": -60
    },
    "id": "_J1gfi5fac7y",
    "outputId": "de68ccf1-fc7d-40cd-a6cf-0a1bcab4600f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value of B after B->+ (V[B]): 0.9990234375\n",
      "Value of A after A->B (V[A]): 0.7984382629394532\n"
     ]
    }
   ],
   "source": [
    "# B->+\n",
    "t = 1\n",
    "for _ in range(10): \n",
    "    td_error = R[t] + gamma*V[t+1] - V[t] \n",
    "    V[t] = V[t] + alpha*td_error\n",
    "\n",
    "print(\"Value of B after B->+ (V[B]):\", V[B])\n",
    "\n",
    "# A->B\n",
    "t = 0\n",
    "for _ in range(10): \n",
    "    td_error = R[t] + gamma*V[t+1] - V[t] \n",
    "    V[t] = V[t] + alpha*td_error\n",
    "\n",
    "print(\"Value of A after A->B (V[A]):\", V[A])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kalman TD (Gershman)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N,D=5,2\n",
    "X = np.zeros([N,D])\n",
    "np.vstack((X,np.zeros([1,D])))\n",
    "np.identity(D)\n",
    "\n",
    "A = np.array([1,0])\n",
    "B = np.array([0,1])\n",
    "A@B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "# c - prior variance (default: 1)\n",
    "# s - observation noise variance (default: 1)\n",
    "# q - transition noise variance (default: 0.01)\n",
    "\n",
    "def ktd(X, R, gamma=0.9, c=1, s=1, q=0.005):  \n",
    "    N,D = np.array(X).shape                       # N - time steps ; D - feature dimensions \n",
    "    w = np.zeros(D)                               # weights\n",
    "    X = np.vstack((np.array(X),np.zeros([1,D])))  # add feature vector at end for dummy X[i+1,:]\n",
    "    C = c*np.identity(D)\n",
    "    Q = q*np.identity(D)\n",
    "    \n",
    "    print(\"---------------  KTD:\", N,D, \"\\n\")\n",
    "\n",
    "    for i in range(N):\n",
    "        print(\"i:\", i, \"of\", N, \"--------------------------------\")\n",
    "\n",
    "        h = X[i,:] - gamma*X[i+1,:]                # temporal difference features: a vector Dx1\n",
    "        V = X[i,:]@w                               # value estimate: a real\n",
    "        rhat = h@w                                 # reward prediction: a real\n",
    "        dt = R[i] - rhat                           # prediction error: a real\n",
    "        C = C + Q                                  # a priori covariance: a matrix DxD\n",
    "        P = np.matmul(h,C)@h + s                   # residual covariance: a real\n",
    "        K = np.matmul(C, h.reshape([D,1]) )/P      # Kalman gain: a vector Dx1\n",
    "        w = w + K.flatten()*dt                     # weight update: a vector Dx1\n",
    "        C = C - K*np.matmul(h.reshape([D,1]).T,C)  # posterior covariance update\n",
    "\n",
    "        print(\"rhat:\",rhat)\n",
    "        print(\"dt:\",dt)\n",
    "        print(\"P:\",P)\n",
    "        print(\"K:\",K.flatten().tolist())\n",
    "        print(\"w:\", w.tolist())\n",
    "        print(\"C:\", C.tolist())\n",
    "        print(\"\")\n",
    "        \n",
    "    return w, C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: [[1, 1], [1, 1], [1, 1], [1, 1], [1, 1], [1, 1], [1, 1], [1, 1], [1, 1], [1, 1], [1, 0], [1, 0], [1, 0], [1, 0], [1, 0], [1, 0], [1, 0], [1, 0], [1, 0], [1, 0]]    (20, 2)\n",
      "R: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1] \n",
      "\n",
      "KTD: 20 2 ---------------------------------------------- \n",
      "\n",
      "i: 0 of 20 --------------------------------\n",
      "rhat: 0.0\n",
      "dt: 1.0\n",
      "P: 3.01\n",
      "K: [0.33388704318936874, 0.33388704318936874]\n",
      "w: [0.33388704318936874, 0.33388704318936874]\n",
      "C: [[0.6694435215946843, -0.33555647840531555], [-0.33555647840531555, 0.6694435215946843]]\n",
      "\n",
      "i: 1 of 20 --------------------------------\n",
      "rhat: 0.6677740863787375\n",
      "dt: 0.3322259136212625\n",
      "P: 1.6777740863787376\n",
      "K: [0.20198609928516267, 0.20198609928516267]\n",
      "w: [0.40099205956317696, 0.40099205956317696]\n",
      "C: [[0.6059930496425813, -0.4040069503574186], [-0.4040069503574186, 0.6059930496425813]]\n",
      "\n",
      "i: 2 of 20 --------------------------------\n",
      "rhat: 0.8019841191263539\n",
      "dt: 0.19801588087364608\n",
      "P: 1.4139721985703253\n",
      "K: [0.14638625815588693, 0.14638625815588693]\n",
      "w: [0.42997886341971187, 0.42997886341971187]\n",
      "C: [[0.5806931290779435, -0.4343068709220565], [-0.4343068709220565, 0.5806931290779435]]\n",
      "\n",
      "i: 3 of 20 --------------------------------\n",
      "rhat: 0.8599577268394237\n",
      "dt: 0.14004227316057627\n",
      "P: 1.3027725163117738\n",
      "K: [0.11620314080962534, 0.11620314080962534]\n",
      "w: [0.4462522154070903, 0.4462522154070903]\n",
      "C: [[0.5681015704048127, -0.45189842959518733], [-0.45189842959518733, 0.5681015704048127]]\n",
      "\n",
      "i: 4 of 20 --------------------------------\n",
      "rhat: 0.8925044308141806\n",
      "dt: 0.10749556918581937\n",
      "P: 1.2424062816192507\n",
      "K: [0.09755515776341625, 0.09755515776341625]\n",
      "w: [0.45673896261788116, 0.45673896261788116]\n",
      "C: [[0.5612775788817082, -0.46372242111829187], [-0.46372242111829187, 0.5612775788817082]]\n",
      "\n",
      "i: 5 of 20 --------------------------------\n",
      "rhat: 0.9134779252357623\n",
      "dt: 0.08652207476423768\n",
      "P: 1.2051103155268326\n",
      "K: [0.08510022397292542, 0.08510022397292542]\n",
      "w: [0.46410201055892, 0.46410201055892]\n",
      "C: [[0.5575501119864628, -0.4724498880135373], [-0.4724498880135373, 0.5575501119864628]]\n",
      "\n",
      "i: 6 of 20 --------------------------------\n",
      "rhat: 0.92820402111784\n",
      "dt: 0.07179597888216005\n",
      "P: 1.1802004479458508\n",
      "K: [0.07634315351239332, 0.07634315351239332]\n",
      "w: [0.46958314199629325, 0.46958314199629325]\n",
      "C: [[0.5556715767561967, -0.47932842324380337], [-0.47932842324380337, 0.5556715767561967]]\n",
      "\n",
      "i: 7 of 20 --------------------------------\n",
      "rhat: 0.9391662839925865\n",
      "dt: 0.060833716007413496\n",
      "P: 1.1626863070247868\n",
      "K: [0.06996139287177416, 0.06996139287177416]\n",
      "w: [0.47383915350173783, 0.47383915350173783]\n",
      "C: [[0.5549806964358871, -0.48501930356411294], [-0.48501930356411294, 0.5549806964358871]]\n",
      "\n",
      "i: 8 of 20 --------------------------------\n",
      "rhat: 0.9476783070034757\n",
      "dt: 0.05232169299652434\n",
      "P: 1.1499227857435483\n",
      "K: [0.06518819680862624, 0.06518819680862624]\n",
      "w: [0.4772499103221558, 0.4772499103221558]\n",
      "C: [[0.5550940984043131, -0.4899059015956869], [-0.4899059015956869, 0.5550940984043131]]\n",
      "\n",
      "i: 9 of 20 --------------------------------\n",
      "rhat: 0.9544998206443116\n",
      "dt: 0.0455001793556884\n",
      "P: 1.1403763936172524\n",
      "K: [0.061548272308575736, 0.061548272308575736]\n",
      "w: [0.4800503677512287, 0.4800503677512287]\n",
      "C: [[0.555774136154288, -0.49422586384571215], [-0.49422586384571215, 0.555774136154288]]\n",
      "\n",
      "i: 10 of 20 --------------------------------\n",
      "rhat: 0.4800503677512287\n",
      "dt: 0.5199496322487713\n",
      "P: 1.560774136154288\n",
      "K: [0.3592923044816867, -0.3166543142901339]\n",
      "w: [0.6668642693362953, 0.31540607348608674]\n",
      "C: [[0.3592923044816867, -0.3166543142901339], [-0.3166543142901339, 0.4042753841337749]]\n",
      "\n",
      "i: 11 of 20 --------------------------------\n",
      "rhat: 0.6668642693362953\n",
      "dt: 0.3331357306637047\n",
      "P: 1.3642923044816868\n",
      "K: [0.2670192474772379, -0.23210151757796155]\n",
      "w: [0.7558179214458975, 0.2380847648395978]\n",
      "C: [[0.26701924747723793, -0.23210151757796157], [-0.2321015175779616, 0.33577943723942605]]\n",
      "\n",
      "i: 12 of 20 --------------------------------\n",
      "rhat: 0.7558179214458975\n",
      "dt: 0.24418207855410246\n",
      "P: 1.272019247477238\n",
      "K: [0.21384837377007185, -0.18246698549434875]\n",
      "w: [0.8080358618484883, 0.19352959705408646]\n",
      "C: [[0.21384837377007188, -0.18246698549434875], [-0.18246698549434875, 0.2984285729983118]]\n",
      "\n",
      "i: 13 of 20 --------------------------------\n",
      "rhat: 0.8080358618484883\n",
      "dt: 0.1919641381515117\n",
      "P: 1.218848373770072\n",
      "K: [0.17955340342551604, -0.14970441723604416]\n",
      "w: [0.8425036761892382, 0.16479171762189493]\n",
      "C: [[0.17955340342551604, -0.14970441723604416], [-0.14970441723604416, 0.2761124592700626]]\n",
      "\n",
      "i: 14 of 20 --------------------------------\n",
      "rhat: 0.8425036761892382\n",
      "dt: 0.15749632381076184\n",
      "P: 1.184553403425516\n",
      "K: [0.15579998579365076, -0.1263804711574217]\n",
      "w: [0.8670416012015071, 0.144887258013129]\n",
      "C: [[0.15579998579365076, -0.1263804711574217], [-0.1263804711574217, 0.2621927444854241]]\n",
      "\n",
      "i: 15 of 20 --------------------------------\n",
      "rhat: 0.8670416012015071\n",
      "dt: 0.13295839879849292\n",
      "P: 1.1607999857936508\n",
      "K: [0.13852514452238743, -0.10887359812553245]\n",
      "w: [0.8854596826105335, 0.13041159873492758]\n",
      "C: [[0.13852514452238746, -0.10887359812553245], [-0.10887359812553245, 0.25343324785771554]]\n",
      "\n",
      "i: 16 of 20 --------------------------------\n",
      "rhat: 0.8854596826105335\n",
      "dt: 0.11454031738946646\n",
      "P: 1.1435251445223875\n",
      "K: [0.1255111400128706, -0.09520874870749374]\n",
      "w: [0.8998357684235215, 0.1195063584397173]\n",
      "C: [[0.12551114001287061, -0.09520874870749374], [-0.09520874870749374, 0.24806752881290106]]\n",
      "\n",
      "i: 17 of 20 --------------------------------\n",
      "rhat: 0.8998357684235215\n",
      "dt: 0.10016423157647847\n",
      "P: 1.1305111400128707\n",
      "K: [0.11544436440616125, -0.08421743522705119]\n",
      "w: [0.9113991644740996, 0.11107078375485786]\n",
      "C: [[0.11544436440616125, -0.0842174352270512], [-0.0842174352270512, 0.2450492921855791]]\n",
      "\n",
      "i: 18 of 20 --------------------------------\n",
      "rhat: 0.9113991644740996\n",
      "dt: 0.08860083552590037\n",
      "P: 1.1204443644061612\n",
      "K: [0.107496961234659, -0.07516431685716647]\n",
      "w: [0.9209234850559858, 0.10441116247957939]\n",
      "C: [[0.107496961234659, -0.07516431685716647], [-0.07516431685716647, 0.24371914619927512]]\n",
      "\n",
      "i: 19 of 20 --------------------------------\n",
      "rhat: 0.9209234850559858\n",
      "dt: 0.07907651494401424\n",
      "P: 1.112496961234659\n",
      "K: [0.1011211402409665, -0.06756361543113651]\n",
      "w: [0.9289197924134063, 0.09906846723426749]\n",
      "C: [[0.10112114024096648, -0.0675636154311365], [-0.0675636154311365, 0.24364077320099345]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "A = [1,0]\n",
    "B = [0,1]\n",
    "AB = [1,1]\n",
    "C = [0,0]\n",
    "\n",
    "t = 10\n",
    "X = [AB]*t + [A]*t\n",
    "R = [1]*t + [1]*t\n",
    "\n",
    "print(\"X:\",X, \"  \", np.array(X).shape)\n",
    "print(\"R:\",R, \"\\n\")\n",
    "\n",
    "w,C = ktd(X,R, gamma=0)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "00-AnimalLearning.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
